"use strict";
Object.defineProperty(exports, "__esModule", { value: true });
exports.TokenComputer = exports.TokenTransfer = exports.Token = void 0;
const constants_1 = require("./constants");
const errors_1 = require("./errors");
const utils_codec_1 = require("./utils.codec");
class Token {
    constructor(options) {
        this.identifier = options.identifier;
        this.nonce = options.nonce || 0n;
    }
}
exports.Token = Token;
class TokenTransfer {
    constructor(options) {
        this.token = options.token;
        this.amount = options.amount;
    }
    /**     *
     * @param amount
     * @returns @TokenTransfer from native token
     */
    static newFromNativeAmount(amount) {
        const token = new Token({ identifier: constants_1.EGLD_IDENTIFIER_FOR_MULTI_ESDTNFT_TRANSFER });
        return new TokenTransfer({ token, amount });
    }
    toString() {
        return this.amount.toString();
    }
}
exports.TokenTransfer = TokenTransfer;
class TokenComputer {
    constructor() {
        this.TOKEN_RANDOM_SEQUENCE_LENGTH = 6;
    }
    /**
     * Returns token.nonce == 0
     */
    isFungible(token) {
        return token.nonce === 0n;
    }
    /**
     * Given "FOO-abcdef-0a" returns 10.
     */
    extractNonceFromExtendedIdentifier(identifier) {
        const parts = identifier.split("-");
        const { prefix, ticker, randomSequence } = this.splitIdentifierIntoComponents(parts);
        this.validateExtendedIdentifier(prefix, ticker, randomSequence, parts);
        // If identifier is for a fungible token (2 parts or 3 with prefix), return 0
        if (parts.length === 2 || (prefix && parts.length === 3)) {
            return 0;
        }
        // Otherwise, decode the last part as an unsigned number
        const hexNonce = parts[parts.length - 1];
        return decodeUnsignedNumber(Buffer.from(hexNonce, "hex"));
    }
    /**
     * Given "FOO-abcdef-0a" returns FOO-abcdef.
     */
    extractIdentifierFromExtendedIdentifier(identifier) {
        const parts = identifier.split("-");
        const { prefix, ticker, randomSequence } = this.splitIdentifierIntoComponents(parts);
        this.validateExtendedIdentifier(prefix, ticker, randomSequence, parts);
        if (prefix) {
            this.checkLengthOfPrefix(prefix);
            return prefix + "-" + ticker + "-" + randomSequence;
        }
        return ticker + "-" + randomSequence;
    }
    /**
     * Given "FOO-abcdef-0a" returns FOO.
     * Given "FOO-abcdef" returns FOO.
     */
    extractTickerFromExtendedIdentifier(identifier) {
        const parts = identifier.split("-");
        const { prefix, ticker, randomSequence } = this.splitIdentifierIntoComponents(parts);
        this.validateExtendedIdentifier(prefix, ticker, randomSequence, parts);
        if (prefix) {
            this.checkLengthOfPrefix(prefix);
            return prefix + "-" + ticker + "-" + randomSequence;
        }
        return ticker;
    }
    computeExtendedIdentifier(token) {
        const parts = token.identifier.split("-");
        const { prefix, ticker, randomSequence } = this.splitIdentifierIntoComponents(parts);
        this.validateExtendedIdentifier(prefix, ticker, randomSequence, parts);
        if (token.nonce < 0) {
            throw new Error("The token nonce can't be less than 0");
        }
        if (token.nonce === 0n) {
            return token.identifier;
        }
        const nonceAsHex = utils_codec_1.numberToPaddedHex(token.nonce);
        return `${token.identifier}-${nonceAsHex}`;
    }
    validateExtendedIdentifier(prefix, ticker, randomSequence, parts) {
        this.checkIfExtendedIdentifierWasProvided(prefix, parts);
        this.ensureTokenTickerValidity(ticker);
        this.checkLengthOfRandomSequence(randomSequence);
    }
    splitIdentifierIntoComponents(parts) {
        if (parts.length >= 3 && parts[2].length === this.TOKEN_RANDOM_SEQUENCE_LENGTH) {
            return { prefix: parts[0], ticker: parts[1], randomSequence: parts[2] };
        }
        return { prefix: null, ticker: parts[0], randomSequence: parts[1] };
    }
    checkIfExtendedIdentifierWasProvided(prefix, tokenParts) {
        //  this is for the identifiers of fungible tokens
        const MIN_EXTENDED_IDENTIFIER_LENGTH_IF_SPLITTED = 2;
        //  this is for the identifiers of nft, sft and meta-esdt
        const MAX_EXTENDED_IDENTIFIER_LENGTH_IF_SPLITTED = prefix ? 4 : 3;
        if (tokenParts.length < MIN_EXTENDED_IDENTIFIER_LENGTH_IF_SPLITTED ||
            tokenParts.length > MAX_EXTENDED_IDENTIFIER_LENGTH_IF_SPLITTED) {
            throw new errors_1.ErrInvalidTokenIdentifier("Invalid extended token identifier provided");
        }
    }
    checkLengthOfRandomSequence(randomSequence) {
        if (randomSequence.length !== this.TOKEN_RANDOM_SEQUENCE_LENGTH) {
            throw new errors_1.ErrInvalidTokenIdentifier("The identifier is not valid. The random sequence does not have the right length");
        }
    }
    checkLengthOfPrefix(prefix) {
        const MAX_TOKEN_PREFIX_LENGTH = 4;
        const MIN_TOKEN_PREFIX_LENGTH = 1;
        if (prefix.length < MIN_TOKEN_PREFIX_LENGTH || prefix.length > MAX_TOKEN_PREFIX_LENGTH) {
            throw new errors_1.ErrInvalidTokenIdentifier("The identifier is not valid. The prefix does not have the right length");
        }
    }
    ensureTokenTickerValidity(ticker) {
        const MIN_TICKER_LENGTH = 3;
        const MAX_TICKER_LENGTH = 10;
        if (ticker.length < MIN_TICKER_LENGTH || ticker.length > MAX_TICKER_LENGTH) {
            throw new errors_1.ErrInvalidTokenIdentifier(`The token ticker should be between ${MIN_TICKER_LENGTH} and ${MAX_TICKER_LENGTH} characters`);
        }
        if (!ticker.match(/^[a-zA-Z0-9]+$/)) {
            throw new errors_1.ErrInvalidTokenIdentifier("The token ticker should only contain alphanumeric characters");
        }
    }
}
exports.TokenComputer = TokenComputer;
function decodeUnsignedNumber(arg) {
    return arg.readUIntBE(0, arg.length);
}
//# sourceMappingURL=tokens.js.map